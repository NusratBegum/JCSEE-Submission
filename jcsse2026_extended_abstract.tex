% JCSSE Bangkok 2026 - Extended Abstract Template (Poster Session)
% The 23rd International Joint Conference on Computer Science and Software Engineering
% 24-27 June 2026, Bangkok, Thailand
% https://jcsse2026.org/
%
% IEEE Conference Proceedings format - A4 paper, Times New Roman 10pt
% Extended Abstract: 1-2 pages | Full Paper: up to 6 pages
% BLIND REVIEW: Do NOT include author names/affiliations until camera-ready

\documentclass[10pt,twocolumn,a4paper]{article}

% ===== PACKAGES =====
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{times}                      % Times New Roman font
\usepackage{mathptmx}                   % Times for math
\usepackage{graphicx}                   % For figures
\usepackage{amsmath,amssymb}            % Math support
\usepackage{caption}                    % Caption styling
\usepackage{array}                      % Table improvements
\usepackage{booktabs}                   % Professional tables
\usepackage{enumitem}                   % List customization
\usepackage{hyperref}                   % Hyperlinks (disabled for IEEE style)
\usepackage{xcolor}                     % Color support
\usepackage{balance}                    % Balance last page columns
\usepackage{titlesec}                   % Section formatting
\usepackage{fancyhdr}                   % Header/footer control
\usepackage{flushend}                   % Balance final page columns

% ===== PAGE LAYOUT (A4 Paper - IEEE Standard) =====
% A4: 210mm x 297mm
% Top margin: 19mm, Bottom: 43mm, Left/Right: 13mm
% Column width: 88mm, Column gap: 6mm
\usepackage[
    a4paper,
    top=19mm,
    bottom=43mm,
    left=13mm,
    right=13mm,
    columnsep=6mm
]{geometry}

% ===== NO PAGE NUMBERS =====
\pagestyle{empty}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

% ===== HYPERREF SETUP (disable visible links per IEEE style) =====
\hypersetup{
    colorlinks=false,
    pdfborder={0 0 0},
    hidelinks
}

% ===== SECTION FORMATTING =====
% First-order headings: 10pt small caps, centered, 12pt before, 6pt after
\titleformat{\section}
    {\normalfont\normalsize\scshape\centering}
    {}
    {0pt}
    {}
\titlespacing*{\section}{0pt}{12pt}{6pt}

% Second-order headings: 10pt italic, flush left, Roman numerals, 9pt before, 3pt after
\titleformat{\subsection}
    {\normalfont\normalsize\itshape}
    {\Roman{subsection}.}
    {0.5em}
    {}
\titlespacing*{\subsection}{0pt}{9pt}{3pt}

% Reset subsection numbering within sections
\renewcommand{\thesubsection}{\Roman{subsection}}

% ===== CAPTION FORMATTING =====
% 10pt Times, small caps, left-justified
\captionsetup{
    font=small,
    labelfont={sc},
    justification=justified,
    singlelinecheck=false,
    skip=6pt
}
\captionsetup[figure]{position=below}
\captionsetup[table]{position=above}

% ===== PARAGRAPH FORMATTING =====
\setlength{\parindent}{1pc}             % 1 pica indent (~0.17 inch)
\setlength{\parskip}{0pt}               % No space between paragraphs

% ===== LIST FORMATTING =====
\setlist[itemize]{
    leftmargin=0.5in,
    topsep=0pt,
    partopsep=0pt,
    parsep=0pt,
    itemsep=0pt
}
\setlist[enumerate]{
    leftmargin=0.5in,
    topsep=0pt,
    partopsep=0pt,
    parsep=0pt,
    itemsep=0pt
}

% ===== CUSTOM COMMANDS =====
% Title formatting (24pt, centered)
\newcommand{\papertitle}[1]{%
    \twocolumn[%
        \begin{center}
            {\fontsize{24pt}{28pt}\selectfont #1 \par}
            \vspace{12pt}
        \end{center}
    ]
}

% Author block
\newcommand{\authorblock}[3]{%
    \begin{tabular}{c}
        \textbf{#1} \\
        \textit{#2} \\
        #3
    \end{tabular}
}

% Abstract environment (10pt bold italic)
\renewenvironment{abstract}{%
    \noindent\textbf{\textit{Abstract}}\textemdash\textbf{\textit{}}%
}{%
    \par\vspace{6pt}
}

% Index Terms
\newcommand{\indexterms}[1]{%
    \noindent\textbf{\textit{Index Terms}}\textemdash\textit{#1}%
    \par\vspace{12pt}
}

% Source for figures/tables
\newcommand{\source}[1]{%
    \vspace{1pt}
    {\footnotesize Source: #1}
}

% ===== DOCUMENT =====
\begin{document}

% ===== TITLE =====
\twocolumn[
\begin{center}
    {\fontsize{24pt}{28pt}\selectfont Explainable Adversarial Drift Detection\\[4pt] for MLOps Feature Monitoring\par}
    \vspace{18pt}
    
    % ===== BLIND REVIEW VERSION =====
    % Uncomment the author block below ONLY for camera-ready submission:
    % -----------------------------------------------------------------------
    % \begin{tabular}{ccc}
    %     \begin{tabular}{c}
    %         \textbf{Nusrat Begum} \\
    %         \textit{Faculty of ICT, Mahidol University} \\
    %         nusrat.beg@student.mahidol.edu
    %     \end{tabular}
    %     &
    %     \begin{tabular}{c}
    %         \textbf{Thanapon Noraset} \\
    %         \textit{Faculty of ICT, Mahidol University} \\
    %         thanapon.nor@mahidol.edu
    %     \end{tabular}
    %     &
    %     \begin{tabular}{c}
    %         \textbf{Suppawong Tuarob} \\
    %         \textit{Faculty of ICT, Mahidol University} \\
    %         suppawong.tua@mahidol.edu
    %     \end{tabular}
    % \end{tabular}
    % \vspace{18pt}
    % -----------------------------------------------------------------------
    
\end{center}
]

% ===== ABSTRACT (~150 words) =====
\noindent\textbf{\textit{Abstract}}\textemdash\textit{Machine learning models in production suffer from distribution drift, where evolving input features degrade model performance. Existing unsupervised detectors signal that drift occurred but provide no insight into which features drifted or what corrective action is appropriate. This paper proposes Explainable Adversarial Drift Detection, a framework that extends adversarial validation with permutation testing for statistical rigor and feature attribution for root cause analysis. The framework trains a gradient boosting classifier to distinguish reference from current data, applies a permutation test to confirm statistical significance, and uses feature attribution to identify drifting features with automated remediation prescriptions. Evaluation on synthetic and 13 real-world datasets demonstrated detection of all four temporal drift types with zero missed detections, zero false alarms on stable data, and correct feature identification in all controlled scenarios, advancing drift detection from binary alarms to actionable diagnostics.}

\vspace{6pt}

% ===== INDEX TERMS =====
\noindent\textbf{\textit{Index Terms}}\textemdash\textit{concept drift, adversarial validation, feature attribution, distribution shift, MLOps, streaming data.}

\vspace{12pt}

% ===== INTRODUCTION =====
\section{Introduction and Motivation}

Machine learning models deployed in production frequently encounter evolving data distributions that degrade performance~[1],~[2]. Detecting these changes early is critical, especially when ground-truth labels are delayed or unavailable. The Discriminative Drift Detector (D3)~[3] achieves state-of-the-art accuracy using adversarial validation~[4], but provides no insight into \textit{which} features drifted---a critical gap for practical MLOps deployment.

This work proposes \textbf{Explainable Adversarial Drift Detection (EADD)}, which extends adversarial validation with: (1) permutation testing ($B{=}50$, $\alpha{=}0.01$) for statistically rigorous drift confirmation, (2) SHAP-based feature attribution~[5] identifying which features drive detected drift, and (3) automated prescriptions mapping drift diagnoses to MLOps remediation actions.

% ===== METHODOLOGY =====
\section{Methodology}

EADD operates as a four-step pipeline on streaming data. \textbf{Step 1:} Reservoir sampling maintains a reference window ($W_{ref}{=}500$) capturing the global historical distribution, while a sliding current window ($W_{cur}{=}200$) captures recent observations. \textbf{Step 2:} A LightGBM classifier~[6] is trained to distinguish $W_{ref}$ from $W_{cur}$; high AUC-ROC indicates distributional divergence. \textbf{Step 3:} A permutation test shuffles source labels $B{=}50$ times to build a null distribution; drift is confirmed only if $p < 0.01$. \textbf{Step 4:} Upon confirmation, TreeSHAP extracts per-feature importance from the adversarial classifier, ranking features by drift contribution and classifying the drift pattern (univariate, subset, or multivariate) with corresponding prescriptions.

% ===== RESULTS =====
\section{Key Results}

\textbf{Temporal Coverage:} EADD detected all four drift types (abrupt, gradual, incremental, recurring) with 100\% success rate across 5 runs each; D3 detected only 2/4, failing on gradual and incremental drift entirely.

\textbf{Real-World Performance:} Across 13 benchmark datasets~[4], EADD achieved 0\% missed detection rate with 3.7\% lower mean time to detection than D3 (1,661 vs.\ 1,725 samples).

\textbf{Explainability:} In three controlled scenarios, SHAP correctly identified drifting features as the top contributors in all cases (AUC 0.767--0.801). Feature attribution accuracy was 100\%.

\textbf{Robustness:} EADD produced zero false alarms across all stable stream types, while D3 triggered up to 87.4 false alarms on autocorrelated data (Mann--Whitney $p = 0.0101$).

% ===== CONCLUSION =====
\section{Conclusion}

EADD transforms drift detection from a binary alarm into a diagnostic tool with feature-level attribution and actionable prescriptions. It detects a broader range of drift types than D3, achieves zero false alarms via permutation testing, and correctly identifies drifting features in all tested scenarios. The framework is directly applicable to production MLOps pipelines where understanding \textit{what} drifted is as important as knowing \textit{that} drift occurred.

% ===== REFERENCES =====
\section*{References}
\begin{small}
\begin{enumerate}[label={[\arabic*]}, leftmargin=*, itemsep=1pt, parsep=0pt]
    \item J.~Lu et al., ``Learning under concept drift: A review,'' \textit{IEEE Trans. Knowl. Data Eng.}, vol.~31, no.~12, pp.~2346--2363, 2018.
    
    \item J.~Gama et al., ``A survey on concept drift adaptation,'' \textit{ACM Comput. Surv.}, vol.~46, no.~4, pp.~1--37, 2014.
    
    \item O.~G\"{o}z\"{u}a\c{c}{\i}k et al., ``Unsupervised concept drift detection with a discriminative classifier,'' in \textit{Proc. ACM CIKM}, 2019, pp.~2311--2314.
    
    \item B.~Lukats et al., ``Unsupervised concept drift detection from deep learning representations in real-time,'' in \textit{Proc. CIKM}, 2025.
    
    \item S.~M. Lundberg and S.-I.~Lee, ``A unified approach to interpreting model predictions,'' in \textit{Proc. NeurIPS}, 2017, pp.~4765--4774.
    
    \item G.~Ke et al., ``LightGBM: A highly efficient gradient boosting decision tree,'' in \textit{Proc. NeurIPS}, 2017, pp.~3149--3157.
\end{enumerate}
\end{small}

% Balance columns on last page
\balance

\end{document}
